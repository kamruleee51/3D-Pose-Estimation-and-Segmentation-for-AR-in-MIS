{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detection, Segmentation, and 3D Pose Estimation of Surgical Tools Using Deep Convolutional Neural Networks and Algebraic Geometry**\n",
    "\n",
    "Article link: https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402\n",
    "\n",
    "\n",
    "* This code is written by \n",
    "        ** Md. Kamrul Hasan \n",
    "        ** Medical Imaging and Applications (MAIA)\n",
    "        ** Erasmus Scholar [2017-2019] \n",
    "        ** Contact: kamruleeekuet@gmail.com\n",
    "        \n",
    "        \n",
    "* The outputs of the ART-Net for the test images will be generated from this notebook. The outputs are: <br>\n",
    "\n",
    "&emsp; &emsp; &emsp; 1. Detection sub-network for the tool presence identification.  <br>\n",
    "&emsp; &emsp; &emsp; 2. Segmentation sub-network for getting the surgical instrument masks.  <br>\n",
    "&emsp; &emsp; &emsp; 3. Regression sub-network-1 for edgeLine (tool boundary) extraction.  <br>\n",
    "&emsp; &emsp; &emsp; 4. Regression sub-network-2 for midLine extraction. <br>\n",
    "&emsp; &emsp; &emsp; 5. Regression sub-network-3 for toolTip extraction.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------Create ART-Net Model----------------------------------------------------\n",
    "\n",
    "# Load (Read) the model which saved as yaml file. \n",
    "yaml_file = open('modelSaved.yaml', 'r')  \n",
    "# \"modelSaved.yaml\" is the file name and should be in the same directory of this notebook script. \n",
    "\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)\n",
    "# model.summary() #If you want to see the model summary then uncomment this. Uncomment is preferable. \n",
    "\n",
    "\n",
    "#------------------------Load the traiend Weight to the ART-Net Model---------------------------------------\n",
    "model.load_weights(\"FineTunedmodel.hdf5\")\n",
    "# \"FineTunedmodel.hdf5\" is the saved weights and should be in the same directory of this notebook script. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Setting the current path of this notebook to CurrentDirectory. \n",
    "CurrentDirectory=os.getcwd() \n",
    "\n",
    "# Read all the '.jpg' images that exist in \"Images\" directory of the CurrentDirectory. \n",
    "TestImages = glob.glob(CurrentDirectory+\n",
    "                       '/TestData/kamrul/Troccar/Undistored/first_instrument/'+\"*.png\")\n",
    "TestImages.sort()\n",
    "\n",
    "# if you want to see that Images are reading correctly, please uncomment this. Uncomment is preferable. \n",
    "# print(TestImages)\n",
    "\n",
    "\n",
    "# Set the directory where you want to save the masks and features. e.g. ToolsMaskLilian in CurrentDirectory. \n",
    "MaskSavePath= CurrentDirectory+'/All the Features/'\n",
    "\n",
    "'''\n",
    "Set the numbers of character in your image name. \n",
    "Example: Suppose, your image name is 'image_00001.png', Then\n",
    "        \n",
    "         ImageNameLength = 11 \n",
    "'''\n",
    "\n",
    "ImageNameLength = 9\n",
    "\n",
    "for imageName in TestImages:\n",
    "    \n",
    "    # Read the image and resize to 192x256 (Heigh x Weight)\n",
    "    img = cv2.resize(cv2.imread(imageName,-1),(256,192)) \n",
    "    \n",
    "    # Extract the file name and format of the image \n",
    "    filename, file_extension = os.path.splitext(imageName)\n",
    "    \n",
    "    #Copy the image to temp variable to use later. \n",
    "    temp = img.copy()\n",
    "    \n",
    "    img=img/img.max()\n",
    "    \n",
    "    # Expand the dimension because the model work on the tensor. \n",
    "    '''\n",
    "       For Example: (192, 256, 3) dimensional Image should be (1, 192, 256, 3) dimensional. \n",
    "    '''\n",
    "\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # verbose = 1 for the progress bar  and verbose = 0 for the silent mode \n",
    "    Prediction =model.predict(img,verbose=1) \n",
    "    \n",
    "    \n",
    "    #--------------------------------Save the tool mask-----------------------------------------\n",
    "    mask=(255*(Prediction[0].reshape(192,256))).astype(np.uint8)\n",
    "\n",
    "    colour=cv2.merge((mask, mask, mask))\n",
    "    colour[:,:,0]=0\n",
    "    colour[:,:,2]=0\n",
    "    \n",
    "    overlay_mask=cv2.addWeighted(colour,0.7,temp,0.8,0)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_tool_mask'+file_extension\n",
    "    cv2.imwrite(path,mask)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_tool_overlay'+file_extension\n",
    "    cv2.imwrite(path,overlay_mask)\n",
    "    \n",
    "    \n",
    "    #--------------------------------Save the mid-line-----------------------------------------\n",
    "    midLine=(255*(Prediction[1].reshape(192,256))).astype(np.uint8)\n",
    "\n",
    "    colour=cv2.merge((midLine,midLine,midLine))\n",
    "    colour[:,:,0]=0\n",
    "    colour[:,:,2]=0\n",
    "    \n",
    "    overlay_midLine=cv2.addWeighted(colour,0.7,temp,0.8,0)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_midline'+file_extension\n",
    "    cv2.imwrite(path,midLine)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_midline_overlay'+file_extension\n",
    "    cv2.imwrite(path,overlay_midLine)\n",
    "    \n",
    "\n",
    "    #--------------------------------Save the Tip-Point-----------------------------------------\n",
    "\n",
    "    tipPoint=(255*(Prediction[2].reshape(192,256))).astype(np.uint8)\n",
    "\n",
    "\n",
    "    colour=cv2.merge((tipPoint,tipPoint,tipPoint))\n",
    "    colour[:,:,0]=0\n",
    "    colour[:,:,2]=0\n",
    "    \n",
    "    overlay_tipPoint=cv2.addWeighted(colour,0.7,temp,0.8,0)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_tipPoint'+file_extension\n",
    "    cv2.imwrite(path,tipPoint)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_tipPoint_overlay'+file_extension\n",
    "    cv2.imwrite(path,overlay_tipPoint)   \n",
    "\n",
    "\n",
    "    #--------------------------------Save the Edge-Line-----------------------------------------\n",
    "    \n",
    "    edgeLine=(255*(Prediction[3].reshape(192,256))).astype(np.uint8)\n",
    "    edgeLine [edgeLine<30] = 0\n",
    "\n",
    "    colour=cv2.merge((edgeLine,edgeLine,edgeLine))\n",
    "    colour[:,:,0]=0\n",
    "    colour[:,:,2]=0\n",
    "    \n",
    "    overlay_edgeLine=cv2.addWeighted(colour,0.7,temp,0.8,0)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'_edgeLine'+file_extension\n",
    "    cv2.imwrite(path,edgeLine)\n",
    "    \n",
    "    path=MaskSavePath+filename[-ImageNameLength:]+'__edgeLine_overlay'+file_extension\n",
    "    cv2.imwrite(path,overlay_edgeLine)\n",
    "       \n",
    "\n",
    "    #--------------------------------Save the Tool Flag----------------------------------------\n",
    "\n",
    "    Flag=np.argmax(Prediction[4],axis=1)\n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (50,50)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (0,255,255)\n",
    "    lineType               = 3\n",
    "   \n",
    "    cv2.putText(temp,str(Flag[0]), \n",
    "        bottomLeftCornerOfText, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        lineType)\n",
    "    cv2.imwrite(MaskSavePath+filename[-ImageNameLength:]+'_FLAG'+file_extension, temp )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
